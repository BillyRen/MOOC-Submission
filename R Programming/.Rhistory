license()
1+1
hello world
1
1<=2
install.packages("C:/gbm_2.0-8.zip",repos=NULL)
install.packages("c:/gbm_2.0-8.zip",repos=NULL)
library(gap)
libray(gbm)
library(gbm)
demo()
library(gbm)
install.packages("rattle")
rattle（）
rettle()
rattle()
rattle()
install.packages("knitr")
install.packages("ggplot2")
liabraty(gbm)
liabrary(gbm)
library(gbm)
install.packages("gbm")
library(gbm)
library(gbm)
data(PimaIndiansDiabetes2,package='mlbench')
install.packages("mlbench")
data(PimaIndiansDiabetes2,package='mlbench')
# 将响应变量转为0-1格式
data <- PimaIndiansDiabetes2
data$diabetes <- as.numeric(data$diabetes)
data
data <- transform(data,diabetes=diabetes-1)
head(data)
model <- gbm(diabetes~.,data=data,shrinkage=0.01,
distribution='bernoulli',cv.folds=5,
n.trees=3000,verbose=F)
# 用交叉检验确定最佳迭代次数
best.iter <- gbm.perf(model,method='cv')
# 观察各解释变量的重要程度
summary(model,best.iter)
# 变量的边际效应
plot.gbm(model,1,best.iter)
# 用caret包观察预测精度
library(caret)
install.packages("caret")
# 用caret包观察预测精度
library(caret)
data <- PimaIndiansDiabetes2
fitControl <- trainControl(method = "cv", number = 5,returnResamp = "all")
model2 <- train(diabetes~., data=data,method='gbm',distribution='bernoulli',trControl = fitControl,verbose=F,tuneGrid = data.frame(.n.trees=best.iter,.shrinkage=0.01,.interaction.depth=1))
install.packages("e1071")
fitControl <- trainControl(method = "cv", number = 5,returnResamp = "all")
model2 <- train(diabetes~., data=data,method='gbm',distribution='bernoulli',trControl = fitControl,verbose=F,tuneGrid = data.frame(.n.trees=best.iter,.shrinkage=0.01,.interaction.depth=1))
model2
install.packages("tmcn")
set.seed(31);
heightsCM = rnorm(30,mean=188, sd=5);
weightsK = rnorm(30,mean=84,sd=3);
hasDaughter = sample(c(TRUE,FALSE),size=30,replace=T);
dataFrame = data.frame(heightsCM,weightsK,hasDaughter);
dataFrame
mean(dataFrameSubset$weightsK)
help(subset)
subset(dataFrame, dataFrameSubset, dataFrameSubset$heightsCM >= 188)
dataFramSubset = subset(dataFrame, dataFrameSubset$heightsCM >= 188)
dataFramSubset = subset(dataFrame, dataFrame$heightsCM >= 188)
dataFramSubset
dataFrameSubset$weightsK
dataFramSubset$weightsK
mean(dataFramSubset$weightsK)
set.seed(41)
install.packages("igraph")
library(igraph)
g <- graph.famous("Zachary")
mc <- multilevel.community(g, weights=NA)
plot(mc, g)
library(corrplot)
install.packages("corrplot")
library(corrplot)
corrplt(cor(dataFramX))
dataFrameX
install.packages("tmcn",
+ repos="http://R-Forge.R-project.org")
install.packages("tmcn",+ repos="http://R-Forge.R-project.org")
install.packages("tmcn",repos="http://R-Forge.R-project.org")
d
install.packages("tmcn.crfpp", repos="http://R-Forge.R-project.org")
install.packages("tmcn.crfpp", repos="http://R-Forge.R-project.org")
help(sum)
install.packages("statnet")
library(statnet)
data("Forentine")
data("forentine")
data("C:\Users\Billy\SkyDrive\Desktop\公开课\网络分析\data\forentine")
data("C:/Users/Billy/SkyDrive/Desktop/公开课/网络分析/data/forentine")
load("C:/Users/Billy/SkyDrive/Desktop/公开课/网络分析/data/florentine.dat")
summary(omarriage)
summary(fomarriage)
data("faux.magnolia.high")
data(“florentine”)
data("florentine")
summary(fomarriage)
summary(flomarriage)
model1 <- ergm(flomarriage  edges)
model1 <- ergm(flomarriage~edges)
summary(model1)
model2 <- ergm(flomarriage ~ edges + triangles)
summary(model2)
require(ISLR)
require(boot)
install.packages("ISLR")
require(ISLR)
require(boot)
?cv.glm
plot(mpg~horsepower,data=Auto)
## LOOCV
glm.fit=glm(mpg~horsepower, data=Auto)
cv.glm(Auto,glm.fit)$delta #pretty slow (doesnt use formula (5.2) on page 180)
##Lets write a simple function to use formula (5.2)
loocv=function(fit){
h=lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
## Now we try it out
loocv(glm.fit)
cv.error=rep(0,5)
degree=1:5
for(d in degree){
glm.fit=glm(mpg~poly(horsepower,d), data=Auto)
cv.error[d]=loocv(glm.fit)
}
plot(degree,cv.error,type="b")
## 10-fold CV
cv.error10=rep(0,5)
for(d in degree){
glm.fit=glm(mpg~poly(horsepower,d), data=Auto)
cv.error10[d]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
lines(degree,cv.error10,type="b",col="red")
## Bootstrap
## Minimum risk investment - Section 5.2
alpha=function(x,y){
vx=var(x)
vy=var(y)
cxy=cov(x,y)
(vy-cxy)/(vx+vy-2*cxy)
}
alpha(Portfolio$X,Portfolio$Y)
## What is the standard error of alpha?
alpha.fn=function(data, index){
with(data[index,],alpha(X,Y))
}
alpha.fn(Portfolio,1:100)
set.seed(1)
alpha.fn (Portfolio,sample(1:100,100,replace=TRUE))
boot.out=boot(Portfolio,alpha.fn,R=1000)
boot.out
plot(boot.out)
cv.glmnet()
t_alibaba_data <- read.csv("~/GitHub/Alidata-Competition/data/t_alibaba_data.csv")
View(t_alibaba_data)
t_alibaba_data_tran <- read.csv("~/GitHub/Alidata-Competition/data/t_alibaba_data_tran.csv")
View(t_alibaba_data_tran)
table(t_alibaba_data_tran)
help(table)
t_alibaba_data_tran <- read.csv("~/GitHub/Alidata-Competition/data/t_alibaba_data_tran.csv")
View(t_alibaba_data_tran)
t_alibaba_data_tran$id
t_alibaba_data_tran <- read.csv("~/GitHub/Alidata-Competition/data/t_alibaba_data_tran.csv")
View(t_alibaba_data_tran)
download.file(“https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv”)
library(XML)
fileURL <- "C:/Users/Billy/SkyDrive/Desktop/getdata-data-restaurants.xml"
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
doc
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[1]
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[2]]
rootNode[[2]][[2]]
rootNode[[1]][[2]]
rootNode[[1]]
rootNode[[1]][[1000]]
rootNode[[1]][[1]][[3]]
rootNode[[1]][[1]][[2]]
rootNode[[1]][[1]][[2]][[1]]
rootNode[[1]]
xmlSApply(rootNode,xmlValue)
xmlSApply(rootNode,“//zipcode”,xmlValue)
xmlSApply(rootNode,"//zipcode",xmlValue)
xmlSApply(rootNode[[1]],"//zipcode",xmlValue)
xpathSApply(rootNode[[1]],"//zipcode",xmlValue)
sum(xpathSApply(rootNode[[1]],"//zipcode",xmlValue)==21231)
getdata.data.ss06pid <- read.csv("C:/Users/Billy/SkyDrive/Desktop/getdata-data-ss06pid.csv")
View(getdata.data.ss06pid)
getdata.data.ss06pid$pwgtp15
DT <- getdata.data.ss06pid
DT[,mean(pwgtp15),by=SEX]
DT
DT$SEX
sapply(split(DT$pwgtp15,DT$SEX),mean)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15)）
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15) mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
for(i=1:100){}
for(i=1:100){tapply(DT$pwgtp15,DT$SEX,mean)}
for(iin 1:100){tapply(DT$pwgtp15,DT$SEX,mean)}
for(i in 1:100){tapply(DT$pwgtp15,DT$SEX,mean)}
system.time(for(i in 1:100){tapply(DT$pwgtp15,DT$SEX,mean)})
system.time(for(i in 1:100){sapply(DT$pwgtp15,DT$SEX,mean)})
system.time(for(i in 1:100){sapply(split(DT$pwgtp15,DT$SEX),mean)})
system.time(for(i in 1:100){sapply(split(DT$pwgtp15,DT$SEX),mean)})
system.time(for(i in 1:100){tapply(DT$pwgtp15,DT$SEX,mean)})
system.time(for(i in 1:500){tapply(DT$pwgtp15,DT$SEX,mean)})
system.time(for(i in 1:500){sapply(split(DT$pwgtp15,DT$SEX),mean)})
fread()
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv ')
download.file(”https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv“)
fread()
library(file.table)
library(data.table)
install.packages("data.table")
fread("C:/Users/Billy/SkyDrive/Desktop/getdata-data-ss06pid.csv")
?rpart
?cacheSweave
?shiny
x <- 4
class(x)
x <- c(4, TRUE)
class(x)
x <- c(1,3, 5)
y <- c(3, 2, 10)
rbind(x, y)
class(rbind(x, y))
x <- list(2, "a", "b", TRUE)
x[[2]]
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x > 10] == 4
x[x >= 11] <- 4
x
hw1_data <- read.csv("C:/Users/Billy/SkyDrive/Desktop/hw1_data.csv")
View(hw1_data)
sum(is.na(hw1_data$Ozone))
mean(hw1_data$Ozone,na.rm=T)
mean(hw1_data$Solar.R[hwl_data$Ozone>31 & hwl_data$Temp>90],na.rm=T)
mean(hw1_data$Solar.R[hw1_data$Ozone>31 & hw1_data$Temp>90],na.rm=T)
mean(hw1_data$Temp[hw1_data$Month==6],na.rm=T)
max(hw1_data$Temp[hw1_data$Month==5],na.rm=T)
max(hw1_data$Ozone[hw1_data$Month==5],na.rm=T)
getdata.data.ss06hid <- read.csv("C:/Users/Billy/SkyDrive/Desktop/getdata-data-ss06hid.csv")
View(getdata.data.ss06hid)
nrow(getdata.data.ss06hid$VAL==24)
nrow(getdata.data.ss06hid[getdata.data.ss06hid$VAL==24])
nrow(getdata.data.ss06hid[getdata.data.ss06hid$VAL==24,])
nrow(getdata.data.ss06hid[getdata.data.ss06hid$VAL==24,])
nrow(getdata.data.ss06hid[which(getdata.data.ss06hid$VAL==24）,])
nrow(getdata.data.ss06hid[which(getdata.data.ss06hid$VAL==24),])
getdata.data.ss06hid$VAL==24
nrow(getdata.data.ss06hid[which(getdata.data.ss06hid$VAL==24),],na.rm=T)
nrow(getdata.data.ss06hid[getdata.data.ss06hid$VAL==24,],na.rm=T)
nrow(is.na(getdata.data.ss06hid$VAL==24)
)
nrow(is.na(getdata.data.ss06hid$VAL)
)
sum(is.na(getdata.data.ss06hid$VAL)
)
2076+53
colIndex<-7:15
rowIndex<-18:23
dat <- read.xlsx("C:/Users/Billy/SkyDrive/Desktopgetdata-data-DATA.gov_NGAP.xlsx",1,colIndex,rowIndex)
library(xlsx)
dat <- read.xlsx("C:/Users/Billy/SkyDrive/Desktopgetdata-data-DATA.gov_NGAP.xlsx",1,colIndex,rowIndex)
dat <- read.xlsx("C:/Users/Billy/SkyDrive/Desktopgetdata-data-DATA.gov_NGAP.xlsx",1,colIndex,rowIndex)
dat <- read.xlsx("C:/Users/Billy/SkyDrive/Desktop/getdata-data-DATA.gov_NGAP.xlsx",1,colIndex,rowIndex)
dat <- read.xlsx("C:/Users/Billy/SkyDrive/Desktop/getdata-data-DATA.gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndex,rowIndex=rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
doc<-xmlTreeParse(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml ,useInternal=T)
doc<-xmlTreeParse(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml ,useInternal=T)
doc<-xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml" ,useInternal=T)
fileurl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse( fileurl,useInternal=T)
fileurl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileurl,useInternal=T)
library(XML)
doc<-xmlTreeParse(fileurl,useInternal=T)
fileurl<-"C:/Users/Billy/SkyDrive/Desktop/getdata-data-restaurants.xml"
doc <- xmlTreeParse(fileurl,useInternal=T)
doc[1]
doc[[1]
]
doc[[1]][[1]]
rootNode<-xmlRoot(doc)
names(rootNode)
rootNode[[1]][[1]]
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[1]][[2]]
rootNode[[1]][[1]][[2]]==21231
xmlSApply(rootNode[[1]][[1]][[2]],xmlValue)
xmlSApply(rootNode[[1]][[1]][[2]],xmlValue)==21206
rootNode[[1]][[1]]
xpathSAplly(rootNode,"//zipcode",xmlValue)
xpathSApply(rootNode,"//zipcode",xmlValue)
nrow(xpathSApply(rootNode,"//zipcode",xmlValue)== 21231)
nrow(which(xpathSApply(rootNode,"//zipcode",xmlValue)== 21231))
as.logistic(xpathSApply(rootNode,"//zipcode",xmlValue)== 21231)
as.logical(xpathSApply(rootNode,"//zipcode",xmlValue)== 21231)
sum(as.logical(xpathSApply(rootNode,"//zipcode",xmlValue)== 21231))
library(data.table)
help("data.table")
DT <- fread(""C:/Users/Billy/SkyDrive/Desktop/getdata-data-ss06pid.csv"")
DT <- fread("C:/Users/Billy/SkyDrive/Desktop/getdata-data-ss06pid.csv")
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(for(i in 1:100){DT[,mean(pwgtp15),by=SEX]})
system.time(for(i in 1:100){tapply(DT$pwgtp15,DT$SEX,mean)})
system.time(for(i in 1:100){tapply(sapply(split(DT$pwgtp15,DT$SEX),mean)})
system.time(for(i in 1:100){sapply(split(DT$pwgtp15,DT$SEX),mean)}
)
install.packages("KernSmooth")
library(KernSmooht)
library(KernSmooth)
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
L<-1
h(1,1,3)
L<-1.5
h(1,1,3)
g
L <-1000
g(1,1)
h(1,1)
h(1,1,10)
make.power(n){}
make.power <- function(n){
pow <- function(x){
x^n
}
pow
}
make.power <- function(n){
pow <- function(x){
x^n
}
pow
}
make.power(3)(2)
install.packages("sqldf")
library(sqldf)
getdata.data.ss06pid <- read.csv("C:/Users/Billy/SkyDrive/Desktop/getdata-data-ss06pid.csv")
View(getdata.data.ss06pid)
acs <- getdata.data.ss06pid
sqldf("select * from acs where AGEP < 50")
sqldf("select distinct AGEP from acs")
sqldf("select unique AGEP from acs")
sqldf("select AGEP where unique from acs")
myUrl <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(myUrl)
htmlCode
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
myUrl <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
acs
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
setwd("C:/Users/Billy/SkyDrive/Documents/GitHub/MOOC-Submission/R Programming")
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
submit()
submit()
source("corr.R")
source("complete.R")
cr <- corr("specdata", 150)
head(cr)
submit()
submit()
submit()
